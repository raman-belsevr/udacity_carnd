{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Parameters\n",
    "CAL_INPUT_IMAGE_DIR = \"camera_cal\"\n",
    "CAL_OUTPUT_FILE = \"calibration_params.p\"\n",
    "TEST_IMAGE_DIR = \"test_images\"\n",
    "COLOR_THRESHOLD = (170, 255)\n",
    "GRADIENT_X_THRESHOLD = (20, 100)\n",
    "GRADIENT_MAG_THRESHOLD = (20, 100)\n",
    "GRADIENT_DIR_THRESHOLD =(0.7, 1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Calibrate camera, if not done before\n",
    "class Utils:\n",
    "    \n",
    "    @staticmethod\n",
    "    def calibrate_camera(image_dir, nx, ny, image_size):\n",
    "        '''\n",
    "        Compute and return camera calibration parameters\n",
    "        '''\n",
    "        \n",
    "        if os.path.isfile(CAL_OUTPUT_FILE):\n",
    "            print(\"Calibration has been done before, will skip!\")\n",
    "            cal_params = pickle.load( open( CAL_OUTPUT_FILE, \"rb\" ) )\n",
    "            return cal_params\n",
    "        else: \n",
    "            print(\"Needs calibration, proceeding...\")\n",
    "            objp = np.zeros((ny*nx, 3), np.float32)\n",
    "            objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2)\n",
    "            objpoints = []\n",
    "            imgpoints = []\n",
    "\n",
    "            images = glob.glob(os.path.join(image_dir, '*.jpg'))\n",
    "            for ids, fname in enumerate(images):\n",
    "                img = cv2.imread(fname)\n",
    "                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "                if ret is True:\n",
    "                    objpoints.append(objp)\n",
    "                    imgpoints.append(corners)\n",
    "\n",
    "            any_image = cv2.imread(images[0])\n",
    "            img_size = (any_image.shape[1], any_image.shape[0])\n",
    "            print(\"Image size is {}\".format(img_size))\n",
    "            ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "            \n",
    "            calibration_params = {}\n",
    "            calibration_params[\"mtx\"] = mtx\n",
    "            calibration_params[\"dist\"] = dist\n",
    "            f = open (CAL_OUTPUT_FILE, \"wb\")\n",
    "            pickle.dump(calibration_params, f)\n",
    "            print(\"Camera calibration parameters written to {}\".format(CAL_OUTPUT_FILE))\n",
    "            return calibration_params\n",
    "\n",
    "    @staticmethod\n",
    "    def to_gray_scale(image):\n",
    "        return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "   \n",
    "    @staticmethod\n",
    "    def gradient_x_threshold(gray_image, min_max):\n",
    "        sobelx = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        scaled_sobelx = np.uint8(255 * (abs_sobelx/(np.max(abs_sobelx))))\n",
    "        binary = np.zeros_like(scaled_sobelx)\n",
    "        binary[(scaled_sobelx > min_max[0]) & (scaled_sobelx <= min_max[1])] = 1\n",
    "        return binary\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_mag_threshold(gray_image, min_max):\n",
    "        sobelx = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0)\n",
    "        sobely = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1)\n",
    "        abs_sobelx = np.absolute(sobelx)\n",
    "        abs_sobely = np.absolute(sobely)\n",
    "        grad_mg = np.sqrt(abs_sobelx**2 + abs_sobely**2) \n",
    "        scaled_grad_mag = np.uint8(255 * (grad_mg/(np.max(grad_mg))))\n",
    "        binary = np.zeros_like(scaled_grad_mag)\n",
    "        binary[(scaled_grad_mag > min_max[0]) & (scaled_grad_mag <= min_max[1])] = 1\n",
    "        return binary\n",
    "    \n",
    "    @staticmethod\n",
    "    def color_threshold(image, min_max):\n",
    "        hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "        channel_s = hls[:,:,2]\n",
    "        binary = np.zeros_like(channel_s)\n",
    "        binary[(channel_s > min_max[0]) & (channel_s <=min_max[1])] = 1\n",
    "        return binary\n",
    "    \n",
    "    @staticmethod\n",
    "    def grad_dir_threshold(gray_image, min_max):\n",
    "        sobelx = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0)\n",
    "        sobely = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1)\n",
    "        angle = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "        binary =  np.zeros_like(angle)\n",
    "        binary[(angle > min_max[0]) & (angle <= min_max[1])] = 1\n",
    "        return binary \n",
    "\n",
    "    @staticmethod                       \n",
    "    def get_perspective_src_dst_points(sample_image):\n",
    "        y_size, x_size = sample_image.shape\n",
    "        src_vertices = np.array([(0.15 * x_size,y_size),(0.4 * x_size, 0.6 * y_size), (0.6 * x_size, 0.6 * y_size), (0.85 * x_size, y_size)], dtype=np.int32)\n",
    "        dst_vertices = np.array([(0.15 * x_size,y_size),(0.15 * x_size, 0.6 * y_size), (0.85 * x_size, 0.6 * y_size), (0.85 * x_size, y_size)], dtype=np.int32)\n",
    "        return (src_vertices, dst_vertices)\n",
    "                        \n",
    "    @staticmethod                       \n",
    "    def histogram(image):\n",
    "        return np.sum(image[image.shape[0]/2:,:], axis=0)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_thresholds(image):\n",
    "        color_threshold_img    = Utils.color_threshold(image, COLOR_THRESHOLD)\n",
    "        gray = Utils.to_gray_scale(image)\n",
    "        gradx_binary = Utils.gradient_x_threshold(gray, GRADIENT_X_THRESHOLD)\n",
    "        mag_binary   = Utils.grad_mag_threshold(gray, GRADIENT_MAG_THRESHOLD)\n",
    "        dir_binary   = Utils.grad_dir_threshold(gray, GRADIENT_DIR_THRESHOLD)\n",
    "        combined = np.zeros_like(color_threshold_img)\n",
    "        combined[(gradx_binary == 1) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "        return combined\n",
    "  \n",
    "    @staticmethod\n",
    "    def init_lane_polynomials(warped_binary):\n",
    "        # build histogram\n",
    "        histogram = Utils.histogram(warped_binary)\n",
    "        out_img = np.dstack((warped_binary, warped_binary, warped_binary))*255\n",
    "\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        # initialize x-locations for left and right lane\n",
    "        leftx_base = np.argmax(histogram[0:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "        n_windows = 9\n",
    "        window_height = np.int(warped_binary.shape[0]/n_windows)\n",
    "        non_zero = warped_binary.nonzero()\n",
    "        non_zero_x = np.array(non_zero[0])\n",
    "        non_zero_y = np.array(non_zero[1])\n",
    "        \n",
    "        left_x_current = leftx_base\n",
    "        right_x_current = rightx_base\n",
    "        margin = 100\n",
    "        minpix = 50\n",
    "        \n",
    "        left_lane_inds = []\n",
    "        right_lane_inds = []\n",
    "        \n",
    "        y_max = warped_binary.shape[0]\n",
    "        x_max = warped_binary.shape[1]\n",
    "        for window in range(n_windows):\n",
    "            win_y_high = y_max - windows * window_height\n",
    "            win_y_low  = win_y_high - window_height\n",
    "            \n",
    "            win_xleft_low  = left_x_current - margin\n",
    "            win_xleft_high = left_x_current + margin\n",
    "            win_xright_low  = right_x_current - margin\n",
    "            win_xright_high = right_x_current + margin\n",
    "            \n",
    "            cv2.rectangle(out_img, (win_xleft_low, win_y_low),  (win_xleft_high, win_y_high), (0, 255, 0), 2)\n",
    "            cv2.rectangle(out_img, (win_xright_low, win_y_low), (win_xright_high, win_y_high), (0, 255, 0), 2)\n",
    "            \n",
    "            # Identify the nonzero pixels in x and y within the window\n",
    "            good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "            good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "\n",
    "            # Append these indices to the lists\n",
    "            left_lane_inds.append(good_left_inds)\n",
    "            right_lane_inds.append(good_right_inds)\n",
    "            \n",
    "            # If you found > minpix pixels, recenter next window on their mean position\n",
    "            if len(good_left_inds) > minpix:\n",
    "                left_x_current = np.int(np.mean(nonzero_x[good_left_inds]))\n",
    "            if len(good_right_inds) > minpix:\n",
    "                right_x_current = np.int(np.mean(nonzero_x[good_right_inds]))\n",
    "                \n",
    "        # Concatenate the arrays of indices\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "        # Extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        return left_fit, right_fit\n",
    "\n",
    "    @staticmethod                              \n",
    "    def find_lane_polynomials(warped_binary):\n",
    "        # Assume you now have a new warped binary image \n",
    "        # from the next frame of video (also called \"binary_warped\")\n",
    "        # It's now much easier to find line pixels!\n",
    "        nonzero = warped_binary.nonzero()\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        margin = 100\n",
    "        left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "        right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "        # Again, extract left and right line pixel positions\n",
    "        leftx = nonzerox[left_lane_inds]\n",
    "        lefty = nonzeroy[left_lane_inds] \n",
    "        rightx = nonzerox[right_lane_inds]\n",
    "        righty = nonzeroy[right_lane_inds]\n",
    "        \n",
    "        # Fit a second order polynomial to each\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        return left_fit, right_fit\n",
    "  \n",
    "    @staticmethod\n",
    "    def plot(image, left_fit, right_fit):\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    " \n",
    "    @staticmethod\n",
    "    def plot_pair(img1_with_title, img2_with_title):\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "        f.tight_layout()\n",
    "        ax1.imshow(img1_with_title[0])\n",
    "        ax1.set_title(img1_with_title[1], fontsize=50)\n",
    "        ax2.imshow(img2_with_title[0])\n",
    "        ax2.set_title(img2_with_title[1], fontsize=50)\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_single(image, title):\n",
    "        plt.figure(figsize = (1,1))\n",
    "        plt.imshow(image.squeeze(), cmap = \"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \n",
    "    \n",
    "    def __init__(self):\n",
    "        self.cal_mtx = None\n",
    "        self.cal_dist = None\n",
    "        self.pers_M = None\n",
    "        self.calibration_done = False\n",
    "        self.lanes_initialized = False\n",
    "        self.nx = 9\n",
    "        self.ny = 6\n",
    "    \n",
    "            \n",
    "    def undistort(self, image):\n",
    "        # calibrate camera if not done before\n",
    "        if self.calibration_done is False:\n",
    "            image_size = (image.shape[0], image.shape[1])\n",
    "            cal_params = Utils.calibrate_camera(CAL_INPUT_IMAGE_DIR, self.nx, self.ny, image_size)\n",
    "            self.cal_mtx = cal_params[\"mtx\"]\n",
    "            self.cal_dist = cal_params[\"dist\"]\n",
    "            self.calibration_done = True\n",
    "        \n",
    "        return cv2.undistort(image, self.cal_mtx, self.cal_dist, None, self.cal_mtx)      \n",
    "    \n",
    "    def warp_perspective(self, image_binary):\n",
    "        # evaluate perspective transformation matrix, if not done before\n",
    "        if self.pers_M is None:\n",
    "            src, dst = Utils.get_perspective_src_dst_points(image)\n",
    "            self.pers_M = cv2.getPerspectiveTransform(src, dst)\n",
    "        \n",
    "        warped_binary = cv2.warpPerspective(image_binary, self.pers_M, image_binary.shape, flags=cv2.INTER_LINEAR)\n",
    "        return warped\n",
    "    \n",
    "    def find_lanes(self, warped_binary):\n",
    "        # initialize left and right polynomials (for first image input)\n",
    "        if self.lanes_initialized is False:\n",
    "            left_fit, right_fit =  Utils.init_lane_polynomials(warped_binary)\n",
    "            self.lanes_initialized = True\n",
    "        else:\n",
    "            left_fit, right_fit = Utils.find_lane_polynomials(warped_binary)\n",
    "        return left_fit, right_fit  \n",
    "              \n",
    "    def process(self, image):\n",
    "        undistorted = self.undistort(image)\n",
    "        binary_thresholded = Utils.apply_thresholds(undistorted)\n",
    "        warped = self.warp_perspective(binary_thresholded)\n",
    "        self.find_lanes(warped)\n",
    "        Utils.plot(image, self.left_fit, self.right_fit)\n",
    "        return self.left_fit, self.right_fit\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline()\n",
    "def process_image(image):\n",
    "    return pipeline.process(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration has been done before, will skip!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-9c816e73af55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_thresholded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"thresholded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mwarped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarp_perspective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_thresholded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"warped\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-a5ca3eb24791>\u001b[0m in \u001b[0;36mwarp_perspective\u001b[0;34m(self, image_binary)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# evaluate perspective transformation matrix, if not done before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpers_M\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_perspective_src_dst_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpers_M\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetPerspectiveTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-abd0c506b70f>\u001b[0m in \u001b[0;36mget_perspective_src_dst_points\u001b[0;34m(sample_image)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_perspective_src_dst_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0my_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0msrc_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mdst_vertices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.15\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.85\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "test_images = glob.glob(os.path.join(TEST_IMAGE_DIR, '*.jpg'))\n",
    "test_image = cv2.imread(test_images[0])\n",
    "\n",
    "\n",
    "Utils.plot_single(test_image, \"original\")\n",
    "\n",
    "undistorted = pipeline.undistort(test_image)\n",
    "Utils.plot_single(undistorted, \"undistorted\")\n",
    "\n",
    "binary_thresholded = Utils.apply_thresholds(undistorted)\n",
    "Utils.plot_single(binary_thresholded, \"thresholded\")\n",
    "\n",
    "warped = pipeline.warp_perspective(binary_thresholded)\n",
    "Utils.plot_single(warped, \"warped\")\n",
    "\n",
    "#self.find_lanes(warped)\n",
    "\n",
    "#pipeline(test_image)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "challenge_input = 'challenge_video.mp4'\n",
    "#output = 'test_videos_output/solidYellowLeft.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(challenge_input)\n",
    "output = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
